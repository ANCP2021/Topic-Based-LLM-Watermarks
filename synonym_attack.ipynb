{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topic_watermark_processor import TopicWatermarkLogitsProcessor, TopicWatermarkDetector\n",
    "from watermark_processor import WatermarkLogitsProcessor, WatermarkDetector\n",
    "from transformers import (\n",
    "        AutoTokenizer,\n",
    "        AutoModelForSeq2SeqLM,\n",
    "        AutoModelForCausalLM,\n",
    "        LogitsProcessorList\n",
    "    )\n",
    "import torch\n",
    "from functools import partial\n",
    "from topic_extractions import llm_topic_extraction\n",
    "from pprint import pprint\n",
    "from model import generate, load_model\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args = {\n",
    "    'demo_public': False, \n",
    "    # 'model_name_or_path': 'facebook/opt-125m', \n",
    "    'model_name_or_path': 'facebook/opt-1.3b', \n",
    "    # 'model_name_or_path': 'facebook/opt-2.7b', \n",
    "    # 'model_name_or_path': 'facebook/opt-6.7b',\n",
    "    # 'model_name_or_path': 'facebook/opt-13b',\n",
    "    # 'load_fp16' : True,\n",
    "    'load_fp16' : False,\n",
    "    'prompt_max_length': None, \n",
    "    'max_new_tokens': 170, \n",
    "    'generation_seed': 123, \n",
    "    'use_sampling': True, \n",
    "    'n_beams': 1, \n",
    "    'sampling_temp': 0.7, \n",
    "    'use_gpu': True, \n",
    "    'seeding_scheme': 'simple_1', \n",
    "    'gamma': 0.70, \n",
    "    'delta': 3.5, \n",
    "    'normalizers': '', \n",
    "    'ignore_repeated_bigrams': False, \n",
    "    'detection_z_threshold': 2.0, \n",
    "    'select_green_tokens': True,\n",
    "    'skip_model_load': False,\n",
    "    'seed_separately': True,\n",
    "    'is_topic': True,\n",
    "    'topic_token_mapping': {\n",
    "        \"sports\": list(range(22000)),\n",
    "        \"animals\": list(range(22000, 44000)),\n",
    "        \"turtles\": list(range(44000, 66000)),\n",
    "        # Add more topics and corresponding tokens as needed\n",
    "    },\n",
    "    'detected_topic': \"\",\n",
    "    'random_green_ratio': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_text(text, n_edits, edit_type='insert'):\n",
    "    words = text.split()\n",
    "    for _ in range(n_edits):\n",
    "        if edit_type == 'insert':\n",
    "            pos = random.randint(0, len(words))\n",
    "            words.insert(pos, random.choice(words))\n",
    "        elif edit_type == 'delete' and len(words) > 1:\n",
    "            pos = random.randint(0, len(words) - 1)\n",
    "            words.pop(pos)\n",
    "        elif edit_type == 'modify':\n",
    "            pos = random.randint(0, len(words) - 1)\n",
    "            words[pos] = random.choice(words)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(original_prompt, input_text, args, device=None, tokenizer=None):\n",
    "    \"\"\"Instantiate the WatermarkDetection object and call detect on\n",
    "        the input text returning the scores and outcome of the test\"\"\"\n",
    "    \n",
    "\n",
    "    detected_topics = llm_topic_extraction(original_prompt)\n",
    "    print(f\"FInished detected topics for generated text: {detected_topics}\")\n",
    "    watermark_detector = TopicWatermarkDetector(vocab=list(tokenizer.get_vocab().values()),\n",
    "                                        gamma=args['gamma'],\n",
    "                                        seeding_scheme=args['seeding_scheme'],\n",
    "                                        device=device,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        z_threshold=args['detection_z_threshold'],\n",
    "                                        normalizers=args['normalizers'],\n",
    "                                        ignore_repeated_bigrams=args['ignore_repeated_bigrams'],\n",
    "                                        select_green_tokens=args['select_green_tokens'],\n",
    "                                        topic_token_mapping=args['topic_token_mapping'],\n",
    "                                        )\n",
    "\n",
    "    if len(input_text)-1 > watermark_detector.min_prefix_len:\n",
    "        score_dict = watermark_detector.detect(input_text, detected_topics=detected_topics)\n",
    "       \n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_robustness(original_prompt, output, args, device, tokenizer, num_edits_list, edit_type='insert'):\n",
    "    green_fractions = []\n",
    "    z_scores = []\n",
    "\n",
    "    for n_edits in num_edits_list:\n",
    "        modified_output = modify_text(output, n_edits, edit_type)\n",
    "        detection_result = detect(original_prompt, modified_output, args, device, tokenizer)\n",
    "        scores = detection_result[0][0][1]\n",
    "        scores_dict = eval(scores)\n",
    "        green_fractions.append(scores_dict['green_fraction'])\n",
    "        z_scores.append(scores_dict['z_score'])\n",
    "\n",
    "    return green_fractions, z_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_robustness(num_edits_list, green_fractions, z_scores):\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Number of Edits')\n",
    "    ax1.set_ylabel('Green Fraction', color=color)\n",
    "    ax1.plot(num_edits_list, green_fractions, color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Z-Score', color=color)\n",
    "    ax2.plot(num_edits_list, z_scores, color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.title('Robustness Analysis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = (\n",
    "    \"Sports have been an integral part of human culture for centuries, serving as a means of entertainment, \"\n",
    "    \"physical fitness, and social interaction. They are not merely games but vital activities that contribute \"\n",
    "    \"to the holistic development of individuals and communities. The significance of sports transcends the boundaries \"\n",
    "    \"of competition, impacting physical health, mental well-being, social cohesion, and even economic growth.\\n\"\n",
    "    \"Engaging in sports is one of the most effective ways to maintain physical health. Regular participation in physical \"\n",
    "    \"activities helps in the prevention of chronic diseases such as obesity, cardiovascular diseases, diabetes, and hypertension. \"\n",
    "    \"Sports improve cardiovascular fitness, strengthen muscles, enhance flexibility, and boost overall stamina. For children \"\n",
    "    \"and adolescents, sports are crucial for developing healthy growth patterns and preventing lifestyle-related diseases \"\n",
    "    \"later in life.\\n\"\n",
    "    \"The mental health benefits of sports are equally profound. Physical activity triggers the release of endorphins, \"\n",
    "    \"which are natural mood lifters. This can help reduce stress, anxiety, and depression. Sports also improve cognitive \"\n",
    "    \"function, enhancing concentration, memory, and learning abilities. The discipline and focus required in sports \"\n",
    "    \"can translate into improved academic and professional performance, fostering a sense of accomplishment and boosting self-esteem.\\n\"\n",
    "    \"Sports serve as a powerful tool for social integration. They bring people together, fostering a sense of community and belonging. \"\n",
    "    \"Team sports, in particular, teach essential life skills such as teamwork, leadership, communication, and cooperation. These skills are\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sports', 'mental health', 'physical activity', 'social integration', 'team sports']\n"
     ]
    }
   ],
   "source": [
    "detected_topics = llm_topic_extraction(input_text)\n",
    "print(detected_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output WITHOUT watermark:\n",
      " especially important for children, especially those from disadvantaged backgrounds, who are less likely to have the opportunity to participate in sports.\n",
      "While sports are an essential part of our lives, their impact is not enough to maintain a healthy lifestyle. The Global Sport and Well-Being Report, conducted by the World Health Organization (WHO), indicates that one in six people live with the burden of chronic diseases such as diabetes, cardiovascular disease, obesity, and hypertension.\n",
      "The impact of these diseases is felt across the world, and they are largely preventable. The WHO estimates that 1.7 billion people are overweight or obese and, by 2030, the number of overweight and obese people in the world will increase by 230 million people. The WHO estimates that, in the next decade, the number of overweight and obese people will increase by 526 million people.\n",
      "This\n",
      "\n",
      "Output WITH watermark:\n",
      " particularly important when it comes to maintaining healthy and strong friendships. These activities also foster a sense of community, serving to strengthen ties between different age groups. They foster positive relationships between individuals, helping to prevent aggression and bullying among young children, adolescents, and young adults.\n",
      "Gender and ethnicity, however, also affect athletes. Women, particularly, experience a range of negative experiences during sports training and competition. These experiences include harassment, bullying, and violence. These experiences affect athletes of different gender, ethnicity, and age. Women, particularly, experience a range of negative experiences during sports training and competition. These experiences include harassment, bullying, and violence. These experiences affect athletes of different gender, ethnicity, and age.\n",
      "This situation, however, is changing. Women now make up a growing number of sports athletes and their involvement and involvement increase with the rise\n"
     ]
    }
   ],
   "source": [
    "redecoded_input, truncation_warning, decoded_output_without_watermark, decoded_output_with_watermark = generate(\n",
    "    input_text, \n",
    "    detected_topics,\n",
    "    args, \n",
    "    model=model, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Output WITHOUT watermark:\\n{decoded_output_without_watermark}\\n\")\n",
    "print(f\"Output WITH watermark:\\n{decoded_output_with_watermark}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FInished detected topics for generated text: ['sports', 'mental health', 'sports training', 'physical activity', 'social integration', 'gender and ethnicity', 'women in sports\\nsource: https://www.ncbi.nlm.nih.gov/pmc/articles/pmc5695959']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Population must be a sequence.  For dicts or sets, use sorted(d).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m num_edits_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m30\u001b[39m]\n\u001b[1;32m      2\u001b[0m input_concat \u001b[38;5;241m=\u001b[39m input_text \u001b[38;5;241m+\u001b[39m decoded_output_with_watermark\n\u001b[0;32m----> 4\u001b[0m green_fractions, z_scores \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_robustness\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_concat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoded_output_with_watermark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_edits_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43medit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minsert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m plot_robustness(num_edits_list, green_fractions, z_scores)\n",
      "Cell \u001b[0;32mIn[48], line 7\u001b[0m, in \u001b[0;36manalyze_robustness\u001b[0;34m(original_prompt, output, args, device, tokenizer, num_edits_list, edit_type)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_edits \u001b[38;5;129;01min\u001b[39;00m num_edits_list:\n\u001b[1;32m      6\u001b[0m     modified_output \u001b[38;5;241m=\u001b[39m modify_text(output, n_edits, edit_type)\n\u001b[0;32m----> 7\u001b[0m     detection_result \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodified_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     scores \u001b[38;5;241m=\u001b[39m detection_result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m     scores_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(scores)\n",
      "Cell \u001b[0;32mIn[47], line 21\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(original_prompt, input_text, args, device, tokenizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m watermark_detector \u001b[38;5;241m=\u001b[39m TopicWatermarkDetector(vocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mget_vocab()\u001b[38;5;241m.\u001b[39mvalues()),\n\u001b[1;32m      9\u001b[0m                                     gamma\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m                                     seeding_scheme\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseeding_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                     topic_token_mapping\u001b[38;5;241m=\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic_token_mapping\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m                                     )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_text)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m>\u001b[39m watermark_detector\u001b[38;5;241m.\u001b[39mmin_prefix_len:\n\u001b[0;32m---> 21\u001b[0m     score_dict \u001b[38;5;241m=\u001b[39m \u001b[43mwatermark_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetected_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetected_topics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_dict\n",
      "File \u001b[0;32m~/Desktop/github/Topic-based-LLM-Watermarks/topic_watermark_processor.py:416\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(self, text, tokenized_text, detected_topics, return_prediction, return_scores, z_threshold, **kwargs)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Desktop/github/Topic-based-LLM-Watermarks/topic_watermark_processor.py:301\u001b[0m, in \u001b[0;36m_score_sequence\u001b[0;34m(self, input_ids, detected_topic, return_num_tokens_scored, return_num_green_tokens, return_green_fraction, return_green_token_mask, return_z_score, return_p_value)\u001b[0m\n\u001b[1;32m    256\u001b[0m green_token_count, red_token_count, num_tokens_scored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_topic_specific_token_counts(input_ids, detected_topic)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# if self.ignore_repeated_bigrams:\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m#     # Method that only counts a green/red hit once per unique bigram.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m#     # New num total tokens scored (T) becomes the number unique bigrams.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# Results dictionary\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m score_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_num_tokens_scored:\n\u001b[1;32m    303\u001b[0m     score_dict\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(num_tokens_scored\u001b[38;5;241m=\u001b[39mnum_tokens_scored))\n",
      "File \u001b[0;32m~/Desktop/github/Topic-based-LLM-Watermarks/topic_watermark_processor.py:259\u001b[0m, in \u001b[0;36m_get_topic_specific_token_counts\u001b[0;34m(self, input_ids, detected_topic)\u001b[0m\n\u001b[1;32m    244\u001b[0m def _score_sequence(\n\u001b[1;32m    245\u001b[0m     self,\n\u001b[1;32m    246\u001b[0m     input_ids: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m     return_p_value: bool = True,\n\u001b[1;32m    254\u001b[0m ):\n\u001b[1;32m    256\u001b[0m     green_token_count, red_token_count, num_tokens_scored = self._get_topic_specific_token_counts(input_ids, detected_topic)\n\u001b[0;32m--> 259\u001b[0m     # if self.ignore_repeated_bigrams:\n\u001b[1;32m    260\u001b[0m     #     # Method that only counts a green/red hit once per unique bigram.\n\u001b[1;32m    261\u001b[0m     #     # New num total tokens scored (T) becomes the number unique bigrams.\n\u001b[1;32m    262\u001b[0m     #     # We iterate over all unqiue token bigrams in the input, computing the greenlist\n\u001b[1;32m    263\u001b[0m     #     # induced by the first token in each, and then checking whether the second\n\u001b[1;32m    264\u001b[0m     #     # token falls in that greenlist.\n\u001b[1;32m    265\u001b[0m     #     assert return_green_token_mask is False, \"Can't return the green/red mask when ignoring repeats.\"\n\u001b[1;32m    266\u001b[0m     #     bigram_table = {}\n\u001b[1;32m    267\u001b[0m     #     token_bigram_generator = ngrams(input_ids.cpu().tolist(), 2)\n\u001b[1;32m    268\u001b[0m     #     freq = collections.Counter(token_bigram_generator)\n\u001b[1;32m    269\u001b[0m     #     num_tokens_scored = len(freq.keys())\n\u001b[1;32m    270\u001b[0m     #     for idx, bigram in enumerate(freq.keys()):\n\u001b[1;32m    271\u001b[0m     #         prefix = torch.tensor([bigram[0]], device=self.device)  # expects a 1-d prefix tensor on the randperm device\n\u001b[1;32m    272\u001b[0m     #         greenlist_ids = self._get_greenlist_ids(prefix)\n\u001b[1;32m    273\u001b[0m     #         bigram_table[bigram] = True if bigram[1] in greenlist_ids else False\n\u001b[1;32m    274\u001b[0m     #     green_token_count = sum(bigram_table.values())\n\u001b[1;32m    275\u001b[0m     # else:\n\u001b[1;32m    276\u001b[0m     #     num_tokens_scored = len(input_ids) - self.min_prefix_len\n\u001b[1;32m    277\u001b[0m     #     if num_tokens_scored < 1:\n\u001b[1;32m    278\u001b[0m     #         raise ValueError(\n\u001b[1;32m    279\u001b[0m     #             (\n\u001b[1;32m    280\u001b[0m     #                 f\"Must have at least {1} token to score after \"\n\u001b[1;32m    281\u001b[0m     #                 f\"the first min_prefix_len={self.min_prefix_len} tokens required by the seeding scheme.\"\n\u001b[1;32m    282\u001b[0m     #             )\n\u001b[1;32m    283\u001b[0m     #         )\n\u001b[1;32m    284\u001b[0m     #     # Standard method.\n\u001b[1;32m    285\u001b[0m     #     # Since we generally need at least 1 token (for the simplest scheme)\n\u001b[1;32m    286\u001b[0m     #     # we start the iteration over the token sequence with a minimum\n\u001b[1;32m    287\u001b[0m     #     # num tokens as the first prefix for the seeding scheme,\n\u001b[1;32m    288\u001b[0m     #     # and at each step, compute the greenlist induced by the\n\u001b[1;32m    289\u001b[0m     #     # current prefix and check if the current token falls in the greenlist.\n\u001b[1;32m    290\u001b[0m     #     green_token_count, green_token_mask = 0, []\n\u001b[1;32m    291\u001b[0m     #     for idx in range(self.min_prefix_len, len(input_ids)):\n\u001b[1;32m    292\u001b[0m     #         curr_token = input_ids[idx]\n\u001b[1;32m    293\u001b[0m     #         greenlist_ids = self._get_greenlist_ids(input_ids[:idx])\n\u001b[1;32m    294\u001b[0m     #         if curr_token in greenlist_ids:\n\u001b[1;32m    295\u001b[0m     #             green_token_count += 1\n\u001b[1;32m    296\u001b[0m     #             green_token_mask.append(True)\n\u001b[1;32m    297\u001b[0m     #         else:\n\u001b[1;32m    298\u001b[0m     #             green_token_mask.append(False)\n\u001b[1;32m    299\u001b[0m \n\u001b[1;32m    300\u001b[0m     # Results dictionary\n\u001b[1;32m    301\u001b[0m     score_dict = dict()\n\u001b[1;32m    302\u001b[0m     if return_num_tokens_scored:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/random.py:413\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Sampling without replacement entails tracking either potential\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# selections (the pool) in a list or previous selections in a set.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# too many calls to _randbelow(), making them slower and\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# causing them to eat more entropy than necessary.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(population, _Sequence):\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPopulation must be a sequence.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor dicts or sets, use sorted(d).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    415\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(population)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Population must be a sequence.  For dicts or sets, use sorted(d)."
     ]
    }
   ],
   "source": [
    "num_edits_list = [0, 5, 10, 15, 20, 25, 30]\n",
    "input_concat = input_text + decoded_output_with_watermark\n",
    "\n",
    "green_fractions, z_scores = analyze_robustness(\n",
    "    input_concat,\n",
    "    decoded_output_with_watermark, \n",
    "    args, \n",
    "    device, \n",
    "    tokenizer, \n",
    "    num_edits_list, \n",
    "    edit_type='insert'\n",
    ")\n",
    "\n",
    "plot_robustness(num_edits_list, green_fractions, z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edits_list = [0, 5, 10, 15, 20, 25, 30]\n",
    "input_concat = input_text + decoded_output_with_watermark\n",
    "\n",
    "green_fractions, z_scores = analyze_robustness(\n",
    "    input_concat,\n",
    "    decoded_output_with_watermark, \n",
    "    args, \n",
    "    device, \n",
    "    tokenizer, \n",
    "    num_edits_list, \n",
    "    edit_type='delete'\n",
    ")\n",
    "\n",
    "plot_robustness(num_edits_list, green_fractions, z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edits_list = [0, 5, 10, 15, 20, 25, 30]\n",
    "input_concat = input_text + decoded_output_with_watermark\n",
    "\n",
    "green_fractions, z_scores = analyze_robustness(\n",
    "    input_concat,\n",
    "    decoded_output_with_watermark, \n",
    "    args, \n",
    "    device, \n",
    "    tokenizer, \n",
    "    num_edits_list, \n",
    "    edit_type='modify'\n",
    ")\n",
    "\n",
    "plot_robustness(num_edits_list, green_fractions, z_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
